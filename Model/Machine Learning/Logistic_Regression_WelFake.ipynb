{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPFuZKdpuwgz/LsS37H2apc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kl8rWCl568kN","executionInfo":{"status":"ok","timestamp":1764509375131,"user_tz":-420,"elapsed":114262,"user":{"displayName":"tr√¨nh Kh·∫Øc","userId":"18328923008636067384"}},"outputId":"f5c1526f-95be-4721-b892-c395ccc9f931"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚è≥ ƒêang t·∫£i dataset WELFake...\n","üßπ Pre-processing...\n","‚öôÔ∏è Vectorizing (TF-IDF)...\n","üöÄ Training Logistic Regression...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","üéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\n","\n","==================================================\n","üìä K·∫æT QU·∫¢ CU·ªêI C√ôNG:\n","==================================================\n","{'eval_accuracy': 0.961310973488275, 'eval_precision': 0.9613805053894593, 'eval_recall': 0.961310973488275, 'eval_f1': 0.9613027825808775, 'eval_auc': np.float64(0.9934692191873555), 'eval_loss': 'N/A (LogReg)', 'eval_runtime': 0.01752948760986328, 'eval_samples_per_second': 819818.6005113976, 'eval_steps_per_second': 'N/A'}\n","==================================================\n","\n","‚úÖ ƒê√£ l∆∞u model t·∫°i: /content/drive/MyDrive/WELFake_LogReg_Baseline\n"]}],"source":["# =====================================================\n","# BASELINE: LOGISTIC REGRESSION - WELFAKE\n","# Output Format: HuggingFace Style\n","# =====================================================\n","\n","import os, re, psutil, pickle, time\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","from google.colab import drive\n","\n","# 1. MOUNT DRIVE & SETUP\n","if not os.path.exists('/content/drive'):\n","    try:\n","        drive.mount('/content/drive', force_remount=True)\n","    except ValueError: pass\n","\n","OUTPUT_DIR = \"/content/drive/MyDrive/WELFake_LogReg_Baseline\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# 2. LOAD & CLEAN DATA\n","print(\"‚è≥ ƒêang t·∫£i dataset WELFake...\")\n","dataset = load_dataset(\"davanstrien/WELFake\")\n","df = pd.DataFrame(dataset[\"train\"])\n","\n","def clean_text_ml(s):\n","    if not isinstance(s, str): return \"\"\n","    s = s.lower()\n","    s = re.sub(r'https?://\\S+', '', s)\n","    s = re.sub(r'<.*?>', '', s)\n","    s = re.sub(r'[^a-z0-9\\s]', '', s)\n","    s = re.sub(r'\\s+', ' ', s).strip()\n","    return s\n","\n","print(\"üßπ Pre-processing...\")\n","df['content'] = (df['title'].fillna('') + \" \" + df['text'].fillna('')).apply(clean_text_ml)\n","df = df[df['content'].str.len() > 50]\n","\n","# 3. SPLIT\n","X_train_text, X_test_text, y_train, y_test = train_test_split(\n","    df['content'], df['label'], test_size=0.2, random_state=42, stratify=df['label']\n",")\n","\n","# 4. TF-IDF\n","print(\"‚öôÔ∏è Vectorizing (TF-IDF)...\")\n","vectorizer = TfidfVectorizer(max_features=50000, stop_words='english', ngram_range=(1, 2))\n","X_train = vectorizer.fit_transform(X_train_text)\n","X_test = vectorizer.transform(X_test_text)\n","\n","# 5. TRAIN\n","print(\"üöÄ Training Logistic Regression...\")\n","model = LogisticRegression(solver='liblinear', C=1.0, n_jobs=-1, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# =====================================================\n","# 6. EVALUATION (HuggingFace Style Format)\n","# =====================================================\n","print(\"\\nüéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\")\n","\n","# B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian d·ª± ƒëo√°n\n","start_time = time.time()\n","\n","# D·ª± ƒëo√°n nh√£n v√† x√°c su·∫•t\n","y_pred = model.predict(X_test)\n","y_prob = model.predict_proba(X_test)[:, 1] # L·∫•y x√°c su·∫•t l·ªõp 1 (Real)\n","\n","# K·∫øt th√∫c ƒëo th·ªùi gian\n","end_time = time.time()\n","runtime = end_time - start_time\n","samples_per_second = len(y_test) / runtime\n","\n","# T√≠nh to√°n c√°c ch·ªâ s·ªë\n","accuracy = accuracy_score(y_test, y_pred)\n","precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n","auc = roc_auc_score(y_test, y_prob)\n","\n","# T·∫°o dictionary k·∫øt qu·∫£ gi·ªëng HuggingFace\n","eval_results = {\n","    'eval_accuracy': accuracy,\n","    'eval_precision': precision,\n","    'eval_recall': recall,\n","    'eval_f1': f1,\n","    'eval_auc': auc,\n","    'eval_loss': 'N/A (LogReg)', # Logistic Regression sklearn kh√¥ng tr·∫£ v·ªÅ loss theo epoch nh∆∞ DL\n","    'eval_runtime': runtime,\n","    'eval_samples_per_second': samples_per_second,\n","    'eval_steps_per_second': 'N/A' # Kh√¥ng √°p d·ª•ng cho sklearn\n","}\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"üìä K·∫æT QU·∫¢ CU·ªêI C√ôNG:\")\n","print(\"=\"*50)\n","print(eval_results)\n","print(\"=\"*50)\n","\n","# 7. SAVE\n","with open(os.path.join(OUTPUT_DIR, \"logreg_model.pkl\"), \"wb\") as f:\n","    pickle.dump(model, f)\n","with open(os.path.join(OUTPUT_DIR, \"tfidf_vectorizer.pkl\"), \"wb\") as f:\n","    pickle.dump(vectorizer, f)\n","print(f\"\\n‚úÖ ƒê√£ l∆∞u model t·∫°i: {OUTPUT_DIR}\")"]}]}