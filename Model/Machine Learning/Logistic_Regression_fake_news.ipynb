{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPaXqAaXhk7PZEQ72Vyo0KT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b8LR0T_cBtAz","executionInfo":{"status":"ok","timestamp":1764611629085,"user_tz":-420,"elapsed":53055,"user":{"displayName":"ngo cong","userId":"09373141506726908581"}},"outputId":"30d2d3ae-ac2c-4448-c368-dfd9be259945"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Đang tải dataset GonzaloA/fake_news...\n"]},{"output_type":"stream","name":"stderr","text":["Repo card metadata block was not found. Setting CardData to empty.\n","WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n"]},{"output_type":"stream","name":"stdout","text":["Sử dụng các tập train/val/test có sẵn.\n","Đang làm sạch văn bản...\n","Train size: 32465\n","Test size: 8117\n","\n","Đang tạo vector TF-IDF...\n","\n","Bắt đầu huấn luyện...\n","\n","Đang đánh giá trên tập Test...\n","------------------------------\n","Logistic_Regression_GonzaloA_FakeNews\n","{'eval_accuracy': 0.9714180115806332, 'eval_precision': 0.9714675867668509, 'eval_recall': 0.9714180115806332, 'eval_f1': 0.9714256980480572, 'eval_auc': 0.9937251486279024, 'eval_loss': 'N/A (Logistic Regression)', 'eval_runtime': 0.009164810180664062, 'eval_samples_per_second': 885670.2801248699, 'eval_steps_per_second': 'N/A'}\n","------------------------------\n"]}],"source":["# =====================================================\n","# FAKE NEWS DETECTION – Logistic Regression + GonzaloA/fake_news\n","# Output Format: Dictionary-style (Like Hugging Face Trainer)\n","# =====================================================\n","\n","# 1. CÀI ĐẶT & IMPORT\n","# !pip install -q datasets scikit-learn pandas numpy\n","\n","import re\n","import time\n","import warnings\n","import pandas as pd\n","import numpy as np\n","from datasets import load_dataset\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","from sklearn.model_selection import train_test_split\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# 2. TẢI DATASET\n","print(\"\\nĐang tải dataset GonzaloA/fake_news...\")\n","dataset = load_dataset(\"GonzaloA/fake_news\")\n","\n","# 3. XỬ LÝ DỮ LIỆU\n","def process_data(ds_split):\n","    df = pd.DataFrame(ds_split)\n","    # Ghép title + text\n","    df['content'] = df.get('title', '').fillna('') + \" \" + df.get('text', '').fillna('')\n","    return df\n","\n","if 'validation' in dataset and 'test' in dataset:\n","    print(\"Sử dụng các tập train/val/test có sẵn.\")\n","    train_df = process_data(dataset['train'])\n","    test_df = process_data(dataset['test'])\n","    # Gộp val vào train để tăng dữ liệu cho ML cổ điển\n","    val_df = process_data(dataset['validation'])\n","    train_df = pd.concat([train_df, val_df], ignore_index=True)\n","else:\n","    print(\"Tự chia tập dữ liệu...\")\n","    df = process_data(dataset['train'])\n","    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n","\n","# Hàm làm sạch văn bản\n","def clean_text(text):\n","    if not isinstance(text, str): return \"\"\n","    text = text.lower()\n","    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)\n","    text = re.sub(r'<.*?>', ' ', text)\n","    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n","    text = re.sub(r'\\s+', ' ', text).strip()\n","    return text\n","\n","print(\"Đang làm sạch văn bản...\")\n","train_df['clean_content'] = train_df['content'].apply(clean_text)\n","test_df['clean_content'] = test_df['content'].apply(clean_text)\n","\n","# Lọc mẫu ngắn\n","train_df = train_df[train_df['clean_content'].str.len() > 20]\n","test_df = test_df[test_df['clean_content'].str.len() > 20]\n","\n","print(f\"Train size: {len(train_df)}\")\n","print(f\"Test size: {len(test_df)}\")\n","\n","# 4. TF-IDF VECTORIZATION\n","print(\"\\nĐang tạo vector TF-IDF...\")\n","vectorizer = TfidfVectorizer(\n","    max_features=50000,\n","    ngram_range=(1, 2),\n","    stop_words='english'\n",")\n","\n","X_train = vectorizer.fit_transform(train_df['clean_content'])\n","y_train = train_df['label']\n","\n","X_test = vectorizer.transform(test_df['clean_content'])\n","y_test = test_df['label']\n","\n","# 5. HUẤN LUYỆN LOGISTIC REGRESSION\n","print(\"\\nBắt đầu huấn luyện...\")\n","clf = LogisticRegression(\n","    class_weight='balanced',\n","    solver='liblinear',\n","    random_state=42,\n","    max_iter=1000\n",")\n","clf.fit(X_train, y_train)\n","\n","# 6. ĐÁNH GIÁ & ĐO THỜI GIAN (Format giống Trainer)\n","print(\"\\nĐang đánh giá trên tập Test...\")\n","\n","# Bắt đầu đo thời gian dự đoán\n","start_time = time.time()\n","y_pred = clf.predict(X_test)\n","y_prob = clf.predict_proba(X_test)[:, 1]\n","end_time = time.time()\n","\n","# Tính toán các chỉ số thời gian\n","eval_runtime = end_time - start_time\n","n_samples = len(y_test)\n","eval_samples_per_second = n_samples / eval_runtime\n","\n","# Tính toán các chỉ số hiệu năng\n","acc = accuracy_score(y_test, y_pred)\n","precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n","auc = roc_auc_score(y_test, y_prob)\n","\n","# Tạo dictionary kết quả\n","results = {\n","    'eval_accuracy': acc,\n","    'eval_precision': precision,\n","    'eval_recall': recall,\n","    'eval_f1': f1,\n","    'eval_auc': float(auc), # Chuyển về float thường\n","    'eval_loss': 'N/A (Logistic Regression)',\n","    'eval_runtime': eval_runtime,\n","    'eval_samples_per_second': eval_samples_per_second,\n","    'eval_steps_per_second': 'N/A'\n","}\n","\n","print(\"-\" * 30)\n","print(\"Logistic_Regression_GonzaloA_FakeNews\")\n","print(results)\n","print(\"-\" * 30)"]}]}