{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPZWDWCuCryCBYa0V38yp/1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"2c57ecdeea514730b1a612c961aa8708":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_49a2c79bc9324623afc4f8fe86260b83","IPY_MODEL_2df7ab858fd043158b6592484ecd0b26","IPY_MODEL_2da6dda732c24eb2a2da9d8b240bae68"],"layout":"IPY_MODEL_7baabb92c5294672a1fd94d7215f7c57"}},"49a2c79bc9324623afc4f8fe86260b83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78e0a867cf8244e2b6cdc3f38cfc28d8","placeholder":"‚Äã","style":"IPY_MODEL_245983d3fb444efbb171522d5455d46d","value":"Map:‚Äá100%"}},"2df7ab858fd043158b6592484ecd0b26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c7bac9ef2f742eda1d28206917aa21f","max":47492,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8b4a5c35783f44dc82af8a21b6d17cfa","value":47492}},"2da6dda732c24eb2a2da9d8b240bae68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37970eefec0e4e74885b2e8928ce99cd","placeholder":"‚Äã","style":"IPY_MODEL_fb7d7c4ff76144b3a4e7cd298d6c9e60","value":"‚Äá47492/47492‚Äá[02:33&lt;00:00,‚Äá504.32‚Äáexamples/s]"}},"7baabb92c5294672a1fd94d7215f7c57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78e0a867cf8244e2b6cdc3f38cfc28d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"245983d3fb444efbb171522d5455d46d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c7bac9ef2f742eda1d28206917aa21f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8b4a5c35783f44dc82af8a21b6d17cfa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37970eefec0e4e74885b2e8928ce99cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb7d7c4ff76144b3a4e7cd298d6c9e60":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d384bb9c827549cda477b8e51aa331b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6efd36fd35cf4efba910a8cfd2c6c4fb","IPY_MODEL_b0808d0040a74b15b22186314ce42d82","IPY_MODEL_ed91dd6a8a3844e8b4f7da62fd731b50"],"layout":"IPY_MODEL_120573382948459d9ae3c555d1156e03"}},"6efd36fd35cf4efba910a8cfd2c6c4fb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e9cd6a2f4854768b6518213ebb1c0ef","placeholder":"‚Äã","style":"IPY_MODEL_1125c83dbe604f6b8cee5f6c0e84d3ae","value":"Map:‚Äá100%"}},"b0808d0040a74b15b22186314ce42d82":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b79a937f2c3242f8a21b361a86bddc2f","max":7915,"min":0,"orientation":"horizontal","style":"IPY_MODEL_50cb4a459bb646928de975d82b043fe4","value":7915}},"ed91dd6a8a3844e8b4f7da62fd731b50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_176cebda8f0b424e9211eb75b0f4c616","placeholder":"‚Äã","style":"IPY_MODEL_ddabd6bf0eeb48fdab6b55ac3e8197da","value":"‚Äá7915/7915‚Äá[00:16&lt;00:00,‚Äá431.72‚Äáexamples/s]"}},"120573382948459d9ae3c555d1156e03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e9cd6a2f4854768b6518213ebb1c0ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1125c83dbe604f6b8cee5f6c0e84d3ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b79a937f2c3242f8a21b361a86bddc2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50cb4a459bb646928de975d82b043fe4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"176cebda8f0b424e9211eb75b0f4c616":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddabd6bf0eeb48fdab6b55ac3e8197da":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"884898d884d04a5ea39d6a153881e377":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e0e681022dd4595b4090b425b9ef8b6","IPY_MODEL_6a6be94528c840b8a1e2298664bcb53b","IPY_MODEL_c5ca4eef5df14eeb88d1f790af645699"],"layout":"IPY_MODEL_fb81920c01b14c5cb5e1045dce22dd9b"}},"5e0e681022dd4595b4090b425b9ef8b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a371fb2ca964ccf89f6ec4f85af281b","placeholder":"‚Äã","style":"IPY_MODEL_53fbd05340874d138d67b5ae9402167a","value":"Map:‚Äá100%"}},"6a6be94528c840b8a1e2298664bcb53b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e6f081481264852af1d5790ff2e4b58","max":7916,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45f0371a681d4c86b12d3a6c89980ba7","value":7916}},"c5ca4eef5df14eeb88d1f790af645699":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c9fefb2e332f45dc8aada66f585a4d89","placeholder":"‚Äã","style":"IPY_MODEL_ae9b657a7ef944c8bcb92755031e4ec6","value":"‚Äá7916/7916‚Äá[00:15&lt;00:00,‚Äá473.16‚Äáexamples/s]"}},"fb81920c01b14c5cb5e1045dce22dd9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a371fb2ca964ccf89f6ec4f85af281b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53fbd05340874d138d67b5ae9402167a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e6f081481264852af1d5790ff2e4b58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45f0371a681d4c86b12d3a6c89980ba7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c9fefb2e332f45dc8aada66f585a4d89":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae9b657a7ef944c8bcb92755031e4ec6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":877,"referenced_widgets":["2c57ecdeea514730b1a612c961aa8708","49a2c79bc9324623afc4f8fe86260b83","2df7ab858fd043158b6592484ecd0b26","2da6dda732c24eb2a2da9d8b240bae68","7baabb92c5294672a1fd94d7215f7c57","78e0a867cf8244e2b6cdc3f38cfc28d8","245983d3fb444efbb171522d5455d46d","5c7bac9ef2f742eda1d28206917aa21f","8b4a5c35783f44dc82af8a21b6d17cfa","37970eefec0e4e74885b2e8928ce99cd","fb7d7c4ff76144b3a4e7cd298d6c9e60","d384bb9c827549cda477b8e51aa331b7","6efd36fd35cf4efba910a8cfd2c6c4fb","b0808d0040a74b15b22186314ce42d82","ed91dd6a8a3844e8b4f7da62fd731b50","120573382948459d9ae3c555d1156e03","6e9cd6a2f4854768b6518213ebb1c0ef","1125c83dbe604f6b8cee5f6c0e84d3ae","b79a937f2c3242f8a21b361a86bddc2f","50cb4a459bb646928de975d82b043fe4","176cebda8f0b424e9211eb75b0f4c616","ddabd6bf0eeb48fdab6b55ac3e8197da","884898d884d04a5ea39d6a153881e377","5e0e681022dd4595b4090b425b9ef8b6","6a6be94528c840b8a1e2298664bcb53b","c5ca4eef5df14eeb88d1f790af645699","fb81920c01b14c5cb5e1045dce22dd9b","5a371fb2ca964ccf89f6ec4f85af281b","53fbd05340874d138d67b5ae9402167a","1e6f081481264852af1d5790ff2e4b58","45f0371a681d4c86b12d3a6c89980ba7","c9fefb2e332f45dc8aada66f585a4d89","ae9b657a7ef944c8bcb92755031e4ec6"]},"id":"CCsSVHRMvV79","executionInfo":{"status":"ok","timestamp":1768198676783,"user_tz":-420,"elapsed":1427827,"user":{"displayName":"Phan Khac Lap","userId":"08059574573628490836"}},"outputId":"e01d6efe-84d9-481d-86f8-f07ba6ff0c31"},"outputs":[{"output_type":"stream","name":"stdout","text":["Device: Tesla T4 | VRAM: 15.8 GB\n","Mounted at /content/drive\n","Loading Data...\n","Cleaning text...\n","Dataset cleaned samples: 63323\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/47492 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c57ecdeea514730b1a612c961aa8708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7915 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d384bb9c827549cda477b8e51aa331b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/7916 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"884898d884d04a5ea39d6a153881e377"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at nreimers/MiniLM-L6-H384-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["Detected Config: Layers=6, Dim=384, Heads=12\n","\n","Tham s·ªë hu·∫•n luy·ªán (Prompt Tuning):\n","trainable params: 13,058 || all params: 22,727,044 || trainable%: 0.0575\n","\n","==============================\n","üöÄ TRAINING MiniLM + PROMPT TUNING\n","==============================\n","\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='14845' max='14845' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14845/14845 19:04, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Auc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.210900</td>\n","      <td>0.186088</td>\n","      <td>0.929627</td>\n","      <td>0.934496</td>\n","      <td>0.929627</td>\n","      <td>0.929770</td>\n","      <td>0.981025</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.177700</td>\n","      <td>0.183422</td>\n","      <td>0.930385</td>\n","      <td>0.936590</td>\n","      <td>0.930385</td>\n","      <td>0.930519</td>\n","      <td>0.987570</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.160300</td>\n","      <td>0.159619</td>\n","      <td>0.938598</td>\n","      <td>0.943129</td>\n","      <td>0.938598</td>\n","      <td>0.938723</td>\n","      <td>0.989462</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.143800</td>\n","      <td>0.150419</td>\n","      <td>0.942262</td>\n","      <td>0.946549</td>\n","      <td>0.942262</td>\n","      <td>0.942379</td>\n","      <td>0.990963</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.132300</td>\n","      <td>0.119982</td>\n","      <td>0.953380</td>\n","      <td>0.954976</td>\n","      <td>0.953380</td>\n","      <td>0.953460</td>\n","      <td>0.991666</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","üéØ TEST RESULTS\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='248' max='248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [248/248 00:15]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["eval_loss: 0.11856295168399811\n","eval_accuracy: 0.9574279939363315\n","eval_precision: 0.9583433061328311\n","eval_recall: 0.9574279939363315\n","eval_f1: 0.9574887777842115\n","eval_auc: 0.9912753088092242\n","eval_runtime: 15.1914\n","eval_samples_per_second: 521.086\n","eval_steps_per_second: 16.325\n","epoch: 5.0\n","Saved to: /content/drive/MyDrive/WELFake_MiniLM_PromptTuning/final_prompt_tuning\n"]}],"source":["# =====================================================\n","# FAKE NEWS DETECTION ‚Äì MiniLM + PROMPT TUNING + WELFAKE\n","# =====================================================\n","\n","# 1. INSTALL\n","!pip install -q transformers datasets peft accelerate bitsandbytes scikit-learn pandas numpy psutil\n","\n","# 2. IMPORT\n","import os, re, shutil, psutil, warnings\n","import pandas as pd\n","import numpy as np\n","import torch\n","from datasets import load_dataset, Dataset, DatasetDict\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","from sklearn.utils.class_weight import compute_class_weight\n","from transformers import (\n","    AutoTokenizer, AutoModelForSequenceClassification,\n","    TrainingArguments, Trainer, EarlyStoppingCallback,\n","    DataCollatorWithPadding\n",")\n","from peft import PromptTuningConfig, PromptTuningInit, get_peft_model, TaskType\n","from google.colab import drive\n","\n","warnings.filterwarnings(\"ignore\")\n","\n","# 3. GPU INFO\n","device_name = \"CPU\"\n","if torch.cuda.is_available():\n","    device_name = torch.cuda.get_device_name(0)\n","    print(f\"Device: {device_name} | VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n","else:\n","    print(\"Device: CPU\")\n","\n","# 4. MOUNT GOOGLE DRIVE\n","try:\n","    drive.mount('/content/drive', force_remount=True)\n","except ValueError:\n","    print(\"Drive c√≥ th·ªÉ ƒë√£ ƒë∆∞·ª£c mount, ti·∫øp t·ª•c...\")\n","\n","# 5. OUTPUT DIR\n","OUTPUT_DIR = \"/content/drive/MyDrive/WELFake_MiniLM_PromptTuning\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# 6. LOAD DATA & CLEAN\n","print(\"Loading Data...\")\n","dataset = load_dataset(\"davanstrien/WELFake\")\n","df = pd.DataFrame(dataset[\"train\"])\n","\n","df[\"content\"] = df.get(\"title\",\"\").fillna(\"\") + \" [SEP] \" + df.get(\"text\",\"\").fillna(\"\")\n","\n","def clean_text(t):\n","    if not isinstance(t, str): return \"\"\n","    t = t.lower()\n","    t = re.sub(r'https?://\\S+', ' ', t)\n","    t = re.sub(r'<.*?>', ' ', t)\n","    t = re.sub(r'[^a-z0-9\\s]', ' ', t)\n","    t = re.sub(r'\\s+', ' ', t).strip()\n","    return t\n","\n","print(\"Cleaning text...\")\n","df[\"content\"] = df[\"content\"].apply(clean_text)\n","df = df[df[\"content\"].str.len() > 20].drop_duplicates(subset=[\"content\"])\n","print(\"Dataset cleaned samples:\", len(df))\n","\n","# 7. SPLIT DATA\n","labels = df[\"label\"].values\n","train_df, temp_df = train_test_split(df, test_size=0.25, random_state=42, stratify=labels)\n","val_df, test_df   = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"label\"])\n","\n","train_dataset = Dataset.from_pandas(train_df[[\"content\",\"label\"]])\n","val_dataset   = Dataset.from_pandas(val_df[[\"content\",\"label\"]])\n","test_dataset  = Dataset.from_pandas(test_df[[\"content\",\"label\"]])\n","\n","dataset_dict = DatasetDict({\"train\": train_dataset, \"validation\": val_dataset, \"test\": test_dataset})\n","\n","# 8. TOKENIZER (MiniLM)\n","MODEL_NAME = \"nreimers/MiniLM-L6-H384-uncased\"\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","\n","def tokenize_fn(batch):\n","    return tokenizer(batch[\"content\"], truncation=True, max_length=384, padding=False)\n","\n","tokenized = dataset_dict.map(tokenize_fn, batched=True, remove_columns=[\"content\"])\n","tokenized = tokenized.rename_column(\"label\", \"labels\")\n","data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n","\n","# 9. LOAD MODEL & APPLY PROMPT TUNING\n","base_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2)\n","\n","# --- TR√çCH XU·∫§T C·∫§U H√åNH C·ª¶A MINILM ƒê·ªÇ TR√ÅNH L·ªñI ---\n","# MiniLM d·ª±a tr√™n BERT, th∆∞·ªùng d√πng: num_hidden_layers, hidden_size, num_attention_heads\n","mini_config = base_model.config\n","n_layers = getattr(mini_config, \"num_hidden_layers\", getattr(mini_config, \"n_layers\", 6))\n","hidden_size = getattr(mini_config, \"hidden_size\", getattr(mini_config, \"d_model\", 384))\n","n_heads = getattr(mini_config, \"num_attention_heads\", getattr(mini_config, \"n_heads\", 12))\n","\n","print(f\"Detected Config: Layers={n_layers}, Dim={hidden_size}, Heads={n_heads}\")\n","\n","peft_config = PromptTuningConfig(\n","    task_type=TaskType.SEQ_CLS,\n","    prompt_tuning_init=PromptTuningInit.TEXT,\n","    prompt_tuning_init_text=\"Classify real or fake news:\",\n","    num_virtual_tokens=32,\n","    tokenizer_name_or_path=MODEL_NAME,\n","    # Truy·ªÅn tham s·ªë t∆∞·ªùng minh ƒë·ªÉ tr√°nh l·ªói\n","    num_layers=n_layers,\n","    token_dim=hidden_size,\n","    num_attention_heads=n_heads\n",")\n","\n","model = get_peft_model(base_model, peft_config)\n","print(\"\\nTham s·ªë hu·∫•n luy·ªán (Prompt Tuning):\")\n","model.print_trainable_parameters()\n","\n","# 10. CLASS WEIGHTS\n","class_weights = compute_class_weight(\"balanced\", classes=np.array([0,1]), y=df[\"label\"])\n","class_weights = torch.tensor(class_weights, dtype=torch.float32)\n","\n","# 11. METRICS\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    preds = np.argmax(logits, axis=1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n","    acc = accuracy_score(labels, preds)\n","    probs = torch.softmax(torch.tensor(logits), dim=1)[:,1].numpy()\n","    try:\n","        auc = roc_auc_score(labels, probs)\n","    except:\n","        auc = 0.0\n","    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"auc\": auc}\n","\n","# 12. WEIGHTED TRAINER\n","class WeightedTrainer(Trainer):\n","    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n","        labels = inputs.pop(\"labels\")\n","        outputs = model(**inputs)\n","        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(model.device))\n","        loss = loss_fct(outputs.logits, labels)\n","        return (loss, outputs) if return_outputs else loss\n","\n","# 13. TRAINING ARGS\n","# MiniLM nh·ªè h∆°n DistilBERT, nh∆∞ng Prompt Tuning v·∫´n c·∫ßn LR cao\n","training_args = TrainingArguments(\n","    output_dir=OUTPUT_DIR,\n","    num_train_epochs=5,\n","    per_device_train_batch_size=16,    # MiniLM r·∫•t nh·∫π, c√≥ th·ªÉ tƒÉng batch size l√™n 32\n","    per_device_eval_batch_size=32,\n","    gradient_accumulation_steps=1,\n","    learning_rate=1e-2,                # LR cao cho Prompt Tuning (0.01)\n","    warmup_ratio=0.1,\n","    weight_decay=0.01,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    load_best_model_at_end=True,\n","    metric_for_best_model=\"f1\",\n","    greater_is_better=True,\n","    fp16=torch.cuda.is_available(),\n","    report_to=\"none\"\n",")\n","\n","trainer = WeightedTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized[\"train\"],\n","    eval_dataset=tokenized[\"validation\"],\n","    tokenizer=tokenizer,\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",")\n","\n","# 14. TRAIN\n","print(\"\\n==============================\")\n","print(\"üöÄ TRAINING MiniLM + PROMPT TUNING\")\n","print(\"==============================\\n\")\n","trainer.train()\n","\n","# 15. EVALUATE\n","print(\"\\nüéØ TEST RESULTS\")\n","results = trainer.evaluate(tokenized[\"test\"])\n","for k,v in results.items():\n","    print(f\"{k}: {v}\")\n","\n","# 16. SAVE\n","final_path = os.path.join(OUTPUT_DIR, \"final_prompt_tuning\")\n","trainer.save_model(final_path)\n","tokenizer.save_pretrained(final_path)\n","print(f\"Saved to: {final_path}\")"]}]}